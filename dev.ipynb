{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def make_seq_data(n_samples, seq_len):\n",
    "    # Boundary tasks\n",
    "    data, labels = [], []\n",
    "    for _ in range(n_samples):\n",
    "        input = np.random.permutation(range(seq_len)).tolist()\n",
    "        target = sorted(range(len(input)), key=lambda k: input[k])\n",
    "        data.append(input)\n",
    "        labels.append(target)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, weight_size, answer_seq_len, hidden_size=512, is_GRU=True):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.answer_seq_len = answer_seq_len\n",
    "        self.weight_size = weight_size\n",
    "        self.emb_size = emb_size\n",
    "        self.is_GRU = is_GRU\n",
    "\n",
    "        self.emb = nn.Embedding(input_size, emb_size)  # embed inputs\n",
    "        if is_GRU:\n",
    "            self.enc = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "            self.dec = nn.GRUCell(emb_size, hidden_size) # GRUCell's input is always batch first\n",
    "        else:\n",
    "            self.enc = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "            self.dec = nn.LSTMCell(emb_size, hidden_size) # LSTMCell's input is always batch first\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_size, weight_size, bias=False) # blending encoder\n",
    "        self.W2 = nn.Linear(hidden_size, weight_size, bias=False) # blending decoder\n",
    "        self.vt = nn.Linear(weight_size, 1, bias=False) # scaling sum of enc and dec by v.T\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        y = F.softmax(input, dim=3)  \n",
    "        y_bins = y.argmax(dim=3)  \n",
    "        input = y[:,:,:,1]\n",
    "        #input = torch.squeeze(input,0)\n",
    "        path = {}\n",
    "        for k in range(input.size(1)):\n",
    "            input = input[:,k,:]\n",
    "            \n",
    "            input = self.emb(input.long()) # (bs, L, embd_size)\n",
    "\n",
    "            # Encoding\n",
    "            encoder_states, hc = self.enc(input) # encoder_state: (bs, L, H)\n",
    "            encoder_states = encoder_states.transpose(1, 0) # (L, bs, H)\n",
    "\n",
    "            # Decoding states initialization\n",
    "            decoder_input = Variable(torch.zeros(batch_size, self.emb_size)) # (bs, embd_size)\n",
    "            hidden = Variable(torch.zeros([batch_size, self.hidden_size]))   # (bs, h)\n",
    "            cell_state = encoder_states[-1]                                # (bs, h)\n",
    "\n",
    "            probs = []\n",
    "            # Decoding\n",
    "            for i in range(self.answer_seq_len): # range(M)\n",
    "                if self.is_GRU:\n",
    "                    hidden = self.dec(decoder_input, hidden) # (bs, h), (bs, h)\n",
    "                else:\n",
    "                    hidden, cell_state = self.dec(decoder_input, (hidden, cell_state)) # (bs, h), (bs, h)\n",
    "\n",
    "                # Compute blended representation at each decoder time step\n",
    "                blend1 = self.W1(encoder_states)          # (L, bs, W)\n",
    "                blend2 = self.W2(hidden)                  # (bs, W)\n",
    "                blend_sum = F.tanh(blend1 + blend2)    # (L, bs, W)\n",
    "                out = self.vt(blend_sum).squeeze()        # (L, bs)\n",
    "                out = F.log_softmax(out.transpose(0, 1).contiguous(), -1) # (bs, L)\n",
    "                probs.append(out)\n",
    "\n",
    "            probs = torch.stack(probs, dim=1)           # (bs, M, L)\n",
    "        path[k] = \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = np.array([[[0.69246036, 0.59753674, 0.5689253 , 0.56384754, 0.5495899 ,\n",
    "         0.61832803, 0.5803497 , 0.61829597, 0.5745164 , 0.62113696],\n",
    "        [0.5894812 , 0.5551746 , 0.49092993, 0.5252931 , 0.587854  ,\n",
    "         0.53320426, 0.5182203 , 0.5992091 , 0.50958365, 0.60037696],\n",
    "        [0.5886919 , 0.49092993, 0.5830317 , 0.463785  , 0.59199905,\n",
    "         0.46117648, 0.46119246, 0.5954041 , 0.45702708, 0.59380126],\n",
    "        [0.60557234, 0.5252931 , 0.46378502, 0.5862742 , 0.5896137 ,\n",
    "         0.5020659 , 0.50027835, 0.5985208 , 0.5032851 , 0.5972939 ],\n",
    "        [0.6093323 , 0.5878541 , 0.48655203, 0.52164733, 0.5841894 ,\n",
    "         0.4850552 , 0.58888733, 0.49546102, 0.5827878 , 0.49952856],\n",
    "        [0.61832803, 0.5926625 , 0.4611765 , 0.5020659 , 0.48505518,\n",
    "         0.60978544, 0.59040314, 0.47951713, 0.58687156, 0.48131478],\n",
    "        [0.5908085 , 0.51822037, 0.46119246, 0.5002783 , 0.58888733,\n",
    "         0.4963187 , 0.561206  , 0.5942717 , 0.49203363, 0.5936888 ],\n",
    "        [0.61829597, 0.599209  , 0.47888252, 0.5985209 , 0.495461  ,\n",
    "         0.4795172 , 0.5942717 , 0.6245361 , 0.509626  , 0.48861158],\n",
    "        [0.5745164 , 0.50958365, 0.45702705, 0.5032851 , 0.5827878 ,\n",
    "         0.4894781 , 0.49203363, 0.58865094, 0.5568124 , 0.58771056],\n",
    "        [0.62113696, 0.6003769 , 0.48427382, 0.53866506, 0.49952856,\n",
    "         0.48131478, 0.5936888 , 0.48861155, 0.58771056, 0.6238037 ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import *\n",
    "\n",
    "len(data_0[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69246036 0.59753674 0.5689253  0.56384754 0.5495899  0.61832803\n",
      "  0.5803497  0.61829597 0.5745164  0.62113696]\n",
      " [0.69246036 0.59753674 0.5689253  0.56384754 0.5495899  0.61832803\n",
      "  0.5803497  0.61829597 0.5745164  0.62113696]\n",
      " [0.69246036 0.59753674 0.5689253  0.56384754 0.5495899  0.61832803\n",
      "  0.5803497  0.61829597 0.5745164  0.62113696]\n",
      " [0.60557234 0.5252931  0.46378502 0.5862742  0.5896137  0.5020659\n",
      "  0.50027835 0.5985208  0.5032851  0.5972939 ]\n",
      " [0.60557234 0.5252931  0.46378502 0.5862742  0.5896137  0.5020659\n",
      "  0.50027835 0.5985208  0.5032851  0.5972939 ]\n",
      " [0.69246036 0.59753674 0.5689253  0.56384754 0.5495899  0.61832803\n",
      "  0.5803497  0.61829597 0.5745164  0.62113696]\n",
      " [0.5894812  0.5551746  0.49092993 0.5252931  0.587854   0.53320426\n",
      "  0.5182203  0.5992091  0.50958365 0.60037696]\n",
      " [0.69246036 0.59753674 0.5689253  0.56384754 0.5495899  0.61832803\n",
      "  0.5803497  0.61829597 0.5745164  0.62113696]\n",
      " [0.5908085  0.51822037 0.46119246 0.5002783  0.58888733 0.4963187\n",
      "  0.561206   0.5942717  0.49203363 0.5936888 ]\n",
      " [0.5745164  0.50958365 0.45702705 0.5032851  0.5827878  0.4894781\n",
      "  0.49203363 0.58865094 0.5568124  0.58771056]]\n"
     ]
    }
   ],
   "source": [
    "shuffle(data_0[0])\n",
    "print(data_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(data_0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6925, 0.5975, 0.5689, 0.5638, 0.5496, 0.6183, 0.5803, 0.6183,\n",
       "          0.5745, 0.6211],\n",
       "         [0.5895, 0.5552, 0.4909, 0.5253, 0.5879, 0.5332, 0.5182, 0.5992,\n",
       "          0.5096, 0.6004],\n",
       "         [0.5887, 0.4909, 0.5830, 0.4638, 0.5920, 0.4612, 0.4612, 0.5954,\n",
       "          0.4570, 0.5938],\n",
       "         [0.6056, 0.5253, 0.4638, 0.5863, 0.5896, 0.5021, 0.5003, 0.5985,\n",
       "          0.5033, 0.5973],\n",
       "         [0.6093, 0.5879, 0.4866, 0.5216, 0.5842, 0.4851, 0.5889, 0.4955,\n",
       "          0.5828, 0.4995],\n",
       "         [0.6183, 0.5927, 0.4612, 0.5021, 0.4851, 0.6098, 0.5904, 0.4795,\n",
       "          0.5869, 0.4813],\n",
       "         [0.5908, 0.5182, 0.4612, 0.5003, 0.5889, 0.4963, 0.5612, 0.5943,\n",
       "          0.4920, 0.5937],\n",
       "         [0.6183, 0.5992, 0.4789, 0.5985, 0.4955, 0.4795, 0.5943, 0.6245,\n",
       "          0.5096, 0.4886],\n",
       "         [0.5745, 0.5096, 0.4570, 0.5033, 0.5828, 0.4895, 0.4920, 0.5887,\n",
       "          0.5568, 0.5877],\n",
       "         [0.6211, 0.6004, 0.4843, 0.5387, 0.4995, 0.4813, 0.5937, 0.4886,\n",
       "          0.5877, 0.6238]]])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t = torch.Tensor(data_0)\n",
    "#data_t = torch.squeeze(data_t,0)\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6925, 0.5975, 0.5689, 0.5638, 0.5496, 0.6183, 0.5803, 0.6183, 0.5745,\n",
       "         0.6211]])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Variable(torch.FloatTensor(data_t[:,0,:].cpu().detach().numpy()))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=10\n",
    "emb_size=32\n",
    "emb = nn.Embedding(input_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 32])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(data.long()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=512\n",
    "enc = nn.GRU(emb_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = emb(data.long())\n",
    "encoder_states, hc = enc(input)\n",
    "encoder_states = encoder_states.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = nn.GRUCell(emb_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "decoder_input = Variable(torch.zeros(batch_size, emb_size)) # (bs, embd_size)\n",
    "hidden = Variable(torch.zeros([batch_size, hidden_size]))   # (bs, h)\n",
    "cell_state = encoder_states[-1]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_seq_len = 10\n",
    "W1 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "W2 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "vt = nn.Linear(weight_size, 1, bias=False)\n",
    "\n",
    "for i in range(answer_seq_len): # range(M)\n",
    "    hidden = dec(decoder_input, hidden) # (bs, h), (bs, h)\n",
    "    # Compute blended representation at each decoder time step\n",
    "    blend1 = W1(encoder_states)          # (L, bs, W)\n",
    "    blend2 = W2(hidden)                  # (bs, W)\n",
    "    blend_sum = F.tanh(blend1 + blend2)    # (L, bs, W)\n",
    "    out = vt(blend_sum).squeeze(2)      # (L, bs)\n",
    "    out = F.softmax(out.transpose(0, 1).contiguous(), -1) # (bs, L)\n",
    "    probs.append(out)\n",
    "probs = torch.stack(probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "_v, indices = torch.max(probs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9, 9, 9, 9, 9, 9, 9, 9, 9]])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 1000\n",
    "weight_size = 256\n",
    "emb_size = 32\n",
    "batch_size = 25\n",
    "n_epochs = 1\n",
    "\n",
    "input_seq_len = 20\n",
    "inp_size = input_seq_len\n",
    "input, targets = make_seq_data(total_size, input_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.LongTensor(input))     # (N, L)\n",
    "targets = Variable(torch.LongTensor(targets)) # (N, L)\n",
    "\n",
    "data_split = (int)(total_size * 0.9)\n",
    "train_X = input[:data_split]\n",
    "train_Y = targets[:data_split]\n",
    "test_X = input[data_split:]\n",
    "test_Y = targets[data_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20]) torch.Size([1000, 20])\n"
     ]
    }
   ],
   "source": [
    "print(input.size(), targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNetwork(inp_size, emb_size, weight_size, input_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def train(model, X, Y, batch_size, n_epochs):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    N = X.size(0)\n",
    "    L = X.size(1)\n",
    "    # M = Y.size(1)\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        # for i in range(len(train_batches))\n",
    "        for i in range(0, N-batch_size, batch_size):\n",
    "            x = X[i:i+batch_size] # (bs, L)\n",
    "            y = Y[i:i+batch_size] # (bs, M)\n",
    "\n",
    "            probs = model(x) # (bs, M, L)\n",
    "            outputs = probs.view(-1, L) # (bs*M, L)\n",
    "            # outputs = probs.view(L, -1).t().contiguous() # (bs*M, L)\n",
    "            y = y.view(-1) # (bs*M)\n",
    "            loss = F.nll_loss(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_X, train_Y, batch_size, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = input,targets\n",
    "\n",
    "N = X.size(0)\n",
    "L = X.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[(int)(total_size * 0.9):].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20, 20])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model(X[(int)(total_size * 0.9):])\n",
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 20]), torch.Size([100, 20]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_v, indices = torch.max(probs, 2)\n",
    "_v.size(), indices.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start working with probabilities as input and return a path with Pointer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y[(int)(total_size * 0.99):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if torch.equal(ind.data, y.data) else 0 for ind, y in zip(indices, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504,\n",
       "        -2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504, -2.9504,\n",
       "        -2.9504, -2.9504, -2.9504, -2.9504], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_v[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X, Y):\n",
    "    probs = model(X) # (bs, M, L)\n",
    "    _v, indices = torch.max(probs, 2) # (bs, M)\n",
    "    # show test examples\n",
    "    for i in range(len(indices)):\n",
    "        print('-----')\n",
    "        print('test', [v for v in X[i].data])\n",
    "        print('label', [v for v in Y[i].data])\n",
    "        print('pred', [v for v in indices[i].data])\n",
    "        if i>4: break\n",
    "    correct_count = sum([1 if torch.equal(ind.data, y.data) else 0 for ind, y in zip(indices, Y)])\n",
    "    print('Acc: {:.2f}% ({}/{})'.format(correct_count/len(X)*100, correct_count, len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "test [tensor(12), tensor(1), tensor(19), tensor(11), tensor(15), tensor(9), tensor(5), tensor(4), tensor(0), tensor(3), tensor(17), tensor(8), tensor(16), tensor(18), tensor(13), tensor(14), tensor(7), tensor(2), tensor(10), tensor(6)]\n",
      "label [tensor(8), tensor(1), tensor(17), tensor(9), tensor(7), tensor(6), tensor(19), tensor(16), tensor(11), tensor(5), tensor(18), tensor(3), tensor(0), tensor(14), tensor(15), tensor(4), tensor(12), tensor(10), tensor(13), tensor(2)]\n",
      "pred [tensor(8), tensor(8), tensor(8), tensor(7), tensor(7), tensor(6), tensor(19), tensor(16), tensor(11), tensor(5), tensor(18), tensor(3), tensor(3), tensor(15), tensor(12), tensor(4), tensor(2), tensor(2), tensor(2), tensor(2)]\n",
      "-----\n",
      "test [tensor(19), tensor(3), tensor(7), tensor(8), tensor(16), tensor(6), tensor(15), tensor(11), tensor(0), tensor(12), tensor(4), tensor(13), tensor(1), tensor(14), tensor(17), tensor(10), tensor(2), tensor(9), tensor(18), tensor(5)]\n",
      "label [tensor(8), tensor(12), tensor(16), tensor(1), tensor(10), tensor(19), tensor(5), tensor(2), tensor(3), tensor(17), tensor(15), tensor(7), tensor(9), tensor(11), tensor(13), tensor(6), tensor(4), tensor(14), tensor(18), tensor(0)]\n",
      "pred [tensor(12), tensor(12), tensor(12), tensor(10), tensor(10), tensor(19), tensor(5), tensor(2), tensor(3), tensor(17), tensor(15), tensor(7), tensor(0), tensor(13), tensor(13), tensor(4), tensor(6), tensor(6), tensor(6), tensor(6)]\n",
      "-----\n",
      "test [tensor(12), tensor(11), tensor(13), tensor(17), tensor(19), tensor(14), tensor(5), tensor(2), tensor(3), tensor(8), tensor(7), tensor(6), tensor(9), tensor(15), tensor(1), tensor(10), tensor(4), tensor(18), tensor(16), tensor(0)]\n",
      "label [tensor(19), tensor(14), tensor(7), tensor(8), tensor(16), tensor(6), tensor(11), tensor(10), tensor(9), tensor(12), tensor(15), tensor(1), tensor(0), tensor(2), tensor(5), tensor(13), tensor(18), tensor(3), tensor(17), tensor(4)]\n",
      "pred [tensor(19), tensor(19), tensor(7), tensor(16), tensor(16), tensor(6), tensor(11), tensor(10), tensor(9), tensor(12), tensor(15), tensor(1), tensor(2), tensor(5), tensor(3), tensor(4), tensor(13), tensor(13), tensor(13), tensor(13)]\n",
      "-----\n",
      "test [tensor(18), tensor(14), tensor(1), tensor(10), tensor(5), tensor(17), tensor(0), tensor(6), tensor(7), tensor(15), tensor(16), tensor(4), tensor(12), tensor(8), tensor(2), tensor(13), tensor(19), tensor(3), tensor(11), tensor(9)]\n",
      "label [tensor(6), tensor(2), tensor(14), tensor(17), tensor(11), tensor(4), tensor(7), tensor(8), tensor(13), tensor(19), tensor(3), tensor(18), tensor(12), tensor(15), tensor(1), tensor(9), tensor(10), tensor(5), tensor(0), tensor(16)]\n",
      "pred [tensor(6), tensor(6), tensor(14), tensor(17), tensor(11), tensor(4), tensor(7), tensor(8), tensor(13), tensor(19), tensor(3), tensor(18), tensor(0), tensor(1), tensor(10), tensor(9), tensor(16), tensor(16), tensor(16), tensor(16)]\n",
      "-----\n",
      "test [tensor(19), tensor(2), tensor(17), tensor(3), tensor(15), tensor(9), tensor(16), tensor(0), tensor(7), tensor(1), tensor(12), tensor(6), tensor(8), tensor(4), tensor(14), tensor(10), tensor(18), tensor(11), tensor(13), tensor(5)]\n",
      "label [tensor(7), tensor(9), tensor(1), tensor(3), tensor(13), tensor(19), tensor(11), tensor(8), tensor(12), tensor(5), tensor(15), tensor(17), tensor(10), tensor(18), tensor(14), tensor(4), tensor(6), tensor(2), tensor(16), tensor(0)]\n",
      "pred [tensor(9), tensor(9), tensor(9), tensor(13), tensor(13), tensor(19), tensor(11), tensor(8), tensor(12), tensor(5), tensor(15), tensor(17), tensor(0), tensor(14), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2)]\n",
      "-----\n",
      "test [tensor(11), tensor(8), tensor(16), tensor(6), tensor(19), tensor(3), tensor(1), tensor(0), tensor(15), tensor(14), tensor(13), tensor(4), tensor(12), tensor(17), tensor(2), tensor(10), tensor(7), tensor(9), tensor(5), tensor(18)]\n",
      "label [tensor(7), tensor(6), tensor(14), tensor(5), tensor(11), tensor(18), tensor(3), tensor(16), tensor(1), tensor(17), tensor(15), tensor(0), tensor(12), tensor(10), tensor(9), tensor(8), tensor(2), tensor(13), tensor(19), tensor(4)]\n",
      "pred [tensor(6), tensor(6), tensor(6), tensor(5), tensor(11), tensor(18), tensor(3), tensor(1), tensor(1), tensor(17), tensor(15), tensor(12), tensor(12), tensor(2), tensor(2), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8)]\n",
      "Acc: 0.00% (0/100)\n"
     ]
    }
   ],
   "source": [
    "test(model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
